{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The titles of documents harbor valuable information beyond their themes. By incorporating titles, we have the potential to enrich the context of our analysis. Additionally, I plan to utilize a compact pretrained Word2Vec algorithm for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "path_to_word2vec_model = 'frWiki_no_lem_no_postag_no_phrase_1000_skip_cut100.bin'\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(path_to_word2vec_model, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(sentence):\n",
    "\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]|l\\'', '', sentence)\n",
    "\n",
    "    words = word_tokenize(cleaned_text)\n",
    "\n",
    "    filtered_words = [word.lower() for word in words if word.lower() not in stopwords.words('french')]\n",
    "\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stop_words(sessions[0][0][1][\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_words(document):\n",
    "\n",
    "    representation = [document[0].lower()]\n",
    "\n",
    "    representation += remove_stop_words(document[1][\"title\"])\n",
    "\n",
    "    return representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_words(session):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for document in session:\n",
    "\n",
    "        result += get_document_words(document)\n",
    "\n",
    "    return set(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_representation(session, model):\n",
    "\n",
    "    session_words = get_session_words(session)\n",
    "\n",
    "    return np.array([model[word] for word in session_words if word in model.key_to_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kmapper as km\n",
    "from kmapper.jupyter import display\n",
    "from sklearn.manifold import Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper  = km.KeplerMapper(verbose=1)\n",
    "\n",
    "projected_data = mapper.fit_transform(test, projection=[Isomap(n_components=300, n_jobs=1), UMAP(n_components=2, random_state=42)])\n",
    "\n",
    "G = mapper.map(projected_data, test, clusterer=DBSCAN(metric=\"cosine\", eps=1))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
